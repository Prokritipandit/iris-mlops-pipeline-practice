{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c724e14-6309-483d-8a7c-21fc6a301de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling models with DVC...\n",
      " \u001b[33mWARNING\u001b[39m: failed to collect 'workspace', skipping\n",
      "\u001b[31mERROR\u001b[39m: failed to pull data from the cloud - 'models/model.joblib' does not exist as an output or a stage name in 'dvc.yaml': 'dvc.yaml' does not exist\n",
      "\u001b[0mPull complete.\n",
      "Loading models...\n",
      "Models loaded.\n",
      "Connecting to Feature Store...\n",
      "Model, encoder, and feature store loaded.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from feast import FeatureStore\n",
    "import os\n",
    "\n",
    "# --- DEFINE ABSOLUTE PATHS ---\n",
    "# This is the root of your project\n",
    "BASE_DIR = \"/home/jupyter/\"\n",
    "\n",
    "# Define absolute paths for your model files\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"models/model.joblib\")\n",
    "ENCODER_PATH = os.path.join(BASE_DIR, \"models/label_encoder.joblib\")\n",
    "\n",
    "# This is the correct, nested path to your Feast repo\n",
    "FEAST_REPO_PATH = os.path.join(BASE_DIR, \"feature_repo/feature_repo\")\n",
    "\n",
    "# 1. Pull the DVC-tracked model\n",
    "# We still run this from the notebook's location,\n",
    "# but we need to ensure the notebook is in /home/jupyter/\n",
    "print(\"Pulling models with DVC...\")\n",
    "!dvc pull models/model.joblib models/label_encoder.joblib -f\n",
    "print(\"Pull complete.\")\n",
    "\n",
    "# 2. Load model and encoder using ABSOLUTE paths\n",
    "print(\"Loading models...\")\n",
    "model = joblib.load(MODEL_PATH)\n",
    "le = joblib.load(ENCODER_PATH)\n",
    "print(\"Models loaded.\")\n",
    "\n",
    "# 3. Connect to the feature store using the CORRECT ABSOLUTE path\n",
    "print(\"Connecting to Feature Store...\")\n",
    "store = FeatureStore(repo_path=FEAST_REPO_PATH)\n",
    "print(\"Model, encoder, and feature store loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02184d54-a371-48b2-a533-87877c45df6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching online features...\n",
      "{'iris_id': [1001], 'sepal_width': [2.359999895095825], 'petal_width': [1.090000033378601], 'petal_length': [3.8399999141693115], 'sepal_length': [5.449999809265137]}\n"
     ]
    }
   ],
   "source": [
    "# These are the IDs we want to predict *right now*\n",
    "# (Your augmented data only had '1001', let's add a hypothetical '1002')\n",
    "entity_rows = [\n",
    "    {\"iris_id\": 1001},\n",
    "    # {\"iris_id\": 1002}, # This would return 'None' as it's not in the store\n",
    "]\n",
    "\n",
    "# Define the features we need\n",
    "feature_names = [\n",
    "    \"iris_features:sepal_length\",\n",
    "    \"iris_features:sepal_width\",\n",
    "    \"iris_features:petal_length\",\n",
    "    \"iris_features:petal_width\",\n",
    "]\n",
    "\n",
    "# This is the MAGIC!\n",
    "# Feast fetches the LATEST values from the 'online store' (SQLite)\n",
    "print(\"Fetching online features...\")\n",
    "online_features = store.get_online_features(\n",
    "    features=feature_names,\n",
    "    entity_rows=entity_rows\n",
    ").to_dict()\n",
    "\n",
    "print(online_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be544846-15e6-40b2-ad88-9dbf43a50fac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inference Results for Iris ID: 1001 ---\n",
      "Features: {'sepal_length': 5.449999809265137, 'sepal_width': 2.359999895095825, 'petal_length': 3.8399999141693115, 'petal_width': 1.090000033378601}\n",
      "Predicted Species: versicolor\n"
     ]
    }
   ],
   "source": [
    "# Re-format the features for scikit-learn\n",
    "import pandas as pd\n",
    "features_df = pd.DataFrame.from_dict(online_features)\n",
    "X_inference = features_df[\n",
    "    [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "]\n",
    "\n",
    "# Run prediction\n",
    "predictions_encoded = model.predict(X_inference)\n",
    "predictions_labels = le.inverse_transform(predictions_encoded)\n",
    "\n",
    "print(f\"--- Inference Results for Iris ID: {features_df['iris_id'].values[0]} ---\")\n",
    "print(f\"Features: {X_inference.iloc[0].to_dict()}\")\n",
    "print(f\"Predicted Species: {predictions_labels[0]}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
